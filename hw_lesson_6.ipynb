{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlqOAQmQGXOL",
        "outputId": "25d25578-fb32-47a2-e18b-d47a945427b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 216 kB 15.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 2.9 MB/s \n",
            "\u001b[?25h  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!wget -O imdb.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1vrQ5czMHoO3pEnmofFskymXMkq_u1dPc\"\n",
        "!pip -q install eli5\n",
        "!pip -q install spacy\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqbkG4qoS0AB"
      },
      "source": [
        "# Классификация текстов\n",
        "\n",
        "Начнём с самого простого - анализа тональности текста.\n",
        "\n",
        "Будем классифицировать отзывы с IMDB на положительные/отрицательные.\n",
        "\n",
        "Датасет взят с http://ai.stanford.edu/~amaas/data/sentiment/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWCwUcQ9Z0p2"
      },
      "outputs": [],
      "source": [
        "!unzip 'imdb.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js5kqmWMGqN4"
      },
      "outputs": [],
      "source": [
        "!head train.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R9e3pctHIV2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.tsv\", delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(\"test.tsv\", delimiter=\"\\t\")\n",
        "\n",
        "print('Train size = {}'.format(len(train_df)))\n",
        "print('Test size = {}'.format(len(test_df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oHbJCPPwhjp"
      },
      "source": [
        "Посмотрите глазами на тексты? Какие есть зацепки, как определить, что это за сентимент?\n",
        "\n",
        "Самое простое, как всегда - найти ключевые слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DywUCyMLr_TD"
      },
      "outputs": [],
      "source": [
        "#@title Начинаем классифицировать! { vertical-output: true, display-mode: \"form\" }\n",
        "positive_words = 'love', 'great', 'best', 'wonderful', 'excellent', 'superb', 'perfect' #@param {type:\"raw\"}\n",
        "negative_words = 'worst', 'awful', '1/10', 'crap', 'weak', 'waste', 'bad' #@param {type:\"raw\"}\n",
        "\n",
        "positives_count = test_df.review.apply(lambda text: sum(word in text for word in positive_words))\n",
        "negatives_count = test_df.review.apply(lambda text: sum(word in text for word in negative_words))\n",
        "is_positive = positives_count > negatives_count\n",
        "correct_count = (is_positive == test_df.is_positive).values.sum()\n",
        "\n",
        "accuracy = correct_count / len(test_df)\n",
        "\n",
        "print('Test accuracy = {:.2%}'.format(accuracy))\n",
        "if accuracy > 0.71:\n",
        "    from IPython.display import Image, display\n",
        "    display(Image('https://s3.amazonaws.com/achgen360/t/rmmoZsub.png', width=500))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo8HRABxv1kW"
      },
      "source": [
        "**Задание** Придумайте хорошие ключевые слова или фразы и наберите хотя бы 71% точности на тесте (и не забудьте посмотреть на код классификации!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cNmXA_JTeZB"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "vec = CountVectorizer()\n",
        "bow = vec.fit_transform(test_df.review)\n",
        "model = LogisticRegression()\n",
        "model.fit(bow, test_df.is_positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiArwvZSTm3m"
      },
      "outputs": [],
      "source": [
        "feature_importances = model.coef_[0]\n",
        "feature_names = vec.get_feature_names()\n",
        "df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
        "df = df.sort_values('importance', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maaYlzdXTzaG"
      },
      "outputs": [],
      "source": [
        "df['feature'][:10].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApjmKPiCT62J"
      },
      "outputs": [],
      "source": [
        "df['feature'][-10:].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaIrBClMUHZB"
      },
      "source": [
        "**Задание** Кому-нибудь нравятся эти `<br /><br />`? Лично мне - нет. Напишите регулярку, которая будет их удалять"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09OkUmtde6ny"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "pattern = re.compile('<br />')\n",
        "\n",
        "print(train_df['review'].iloc[3])\n",
        "print(pattern.subn(' ', train_df['review'].iloc[3])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO6D9NuMi4II"
      },
      "source": [
        "Применим ее:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LTwQqs_hD-K"
      },
      "outputs": [],
      "source": [
        "train_df['review'] = train_df['review'].apply(lambda text: pattern.subn(' ', text)[0])\n",
        "test_df['review'] = test_df['review'].apply(lambda text: pattern.subn(' ', text)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ENImvMdUMvU"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGxzf4oXmXqw"
      },
      "source": [
        "Пора переходить к машинке!\n",
        "\n",
        "Как будем представлять текст? Проще всего - мешком слов.\n",
        "\n",
        "Заведём большой-большой словарь - список всех слов в обучающей выборке. Тогда каждое предложение можно представить в виде вектора, в котором будет записано, сколько раз встретилось каждое из возможных слов:\n",
        "\n",
        "![bow](https://raw.githubusercontent.com/DanAnastasyev/DeepNLP-Course/master/Week%2001/Images/BOW.png)\n",
        "\n",
        "Простой и приятный способ сделать это - запихнуть тексты в `CountVectorizer`.\n",
        "\n",
        "Он имеет такую сигнатуру:\n",
        "\n",
        "```python\n",
        "CountVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern=r'(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class ‘numpy.int64'>)\n",
        "```\n",
        "\n",
        "Для начала обратим внимание на параметры `lowercase=True` и `max_df=1.0, min_df=1, max_features=None` - они про то, что по умолчанию все слова будут приводиться к нижнему регистру и в словарь попадут все слова, встречавшиеся в текстах.\n",
        "\n",
        "При желании можно было бы убрать слишком редкие или слишком частотные слова - пока не будем этого делать.\n",
        "\n",
        "Посмотрим на простом примере, как он будет работать:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Odnum4iyGDr"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "dummy_data = ['The movie was excellent',\n",
        "              'the movie was awful']\n",
        "\n",
        "dummy_matrix = vectorizer.fit_transform(dummy_data)\n",
        "\n",
        "print(dummy_matrix.toarray())\n",
        "print(vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3zC1ItWybVc"
      },
      "source": [
        "*Как именно vectorizer определяет границы слов? Обратите внимание на параметр `token_pattern=r'(?u)\\b\\w\\w+\\b'` - как он будет работать?*\n",
        "\n",
        "Запустим его на реальных данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccd2gaCdQq2W"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(train_df['review'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_JC9n6C0bFR"
      },
      "source": [
        "Посмотрим на слова, попавшие в словарь:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stV4ICO3mKsf"
      },
      "outputs": [],
      "source": [
        "vectorizer.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oesbuQ9g0krj"
      },
      "source": [
        "Попробуем кого-нибудь таки сконвертировать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUWtDWcp0g7U"
      },
      "outputs": [],
      "source": [
        "vectorizer.transform([train_df['review'].iloc[3]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZCRef3pyCRC"
      },
      "source": [
        "То, что и хотели - вектор с bow (т.е. bag-of-words) представлением исходного текста.\n",
        "\n",
        "И чем эта информация может помочь? Ну, всё тем же - какие-то слова носят положительный окрас, какие-то - отрицательный. Большинство вообще нейтральный, да.\n",
        "\n",
        "![bow with weights](https://github.com/DanAnastasyev/DeepNLP-Course/raw/master/Week%2001/Images/BOW_weights.png)\n",
        "\n",
        "Хочется, наверное, подобрать коэффициенты, которые будут определять уровень окраса, да? Подбирать нужно по обучающей выборке, а не как мы перед этим делали.\n",
        "\n",
        "Например, для выборки\n",
        "```\n",
        "1   The movie was excellent\n",
        "0   the movie was awful\n",
        "```\n",
        "легко подобрать коэффициенты на глазок: что-нибудь вроде `+1` для `excellent`,  `-1` для `awful` и по нулям всем остальным.\n",
        "\n",
        "Построим линейную модель, которая станет этим заниматься. Она будет учиться строить разделяющую гиперплоскость в пространстве bow-векторов.\n",
        "\n",
        "Проверим, как справится логистическая регрессия с нашей супер-выборкой из пары предложений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6WVgK4LtUn2"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "dummy_data = ['The movie was excellent',\n",
        "              'the movie was awful']\n",
        "dummy_labels = [1, 0]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(dummy_data, dummy_labels)\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "print(classifier.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Y-kq-tv-XY"
      },
      "source": [
        "Получилось что надо.\n",
        "\n",
        "Запустим теперь её на реальных данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvxHIIbSiUXq"
      },
      "outputs": [],
      "source": [
        "model.fit(train_df['review'], train_df['is_positive'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d3BBV_uUu-O"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def eval_model(model, test_df, featrure_name):\n",
        "    preds = model.predict(test_df[featrure_name])\n",
        "    print('Test accuracy = {:.2%}'.format(accuracy_score(test_df['is_positive'], preds)))\n",
        "    \n",
        "eval_model(model, test_df, 'review')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnmmz3u71ctO"
      },
      "source": [
        "Прогресс!\n",
        "\n",
        "Хочется как-то посмотреть, что заинтересовало классификатор. К счастью, сделать это совсем просто:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W1Ngl-aVuYx"
      },
      "outputs": [],
      "source": [
        "import eli5\n",
        "eli5.show_weights(classifier, vec=vectorizer, top=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VgCE9tDk-aO"
      },
      "source": [
        "Посмотрим на конкретные примеры его работы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-4sVWBOWJpo"
      },
      "outputs": [],
      "source": [
        "print('Positive' if test_df['is_positive'].iloc[1] else 'Negative')\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[1], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoZhtlYlW-xG"
      },
      "outputs": [],
      "source": [
        "print('Positive' if test_df['is_positive'].iloc[6] else 'Negative')\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[6], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNNUqZvplhAC"
      },
      "source": [
        "Посмотрим на примеры неправильной классификации, наконец:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf9ZzS8fXKFm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = model.predict(test_df['review'])\n",
        "incorrect_pred_index = np.random.choice(np.where(preds != test_df['is_positive'])[0])\n",
        "\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[incorrect_pred_index],\n",
        "                     vec=vectorizer, targets=['positive'], target_names=['negative', 'positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbFXKNrngP46"
      },
      "source": [
        "## Придумываем новые признаки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz7GSFzIlv4V"
      },
      "source": [
        "### Tf-idf\n",
        "\n",
        "Сейчас мы на все слова смотрим с одинаковым весом - хотя какие-то из них более редкие, какие-то более частые, и эта частотность - полезная, вообще говоря, информация.\n",
        "\n",
        "Самый простой способ добавить статистическую информацию о частотностях - сделать *tf-idf* взвешивание:\n",
        "\n",
        "$$\\text{tf-idf}(t, d) = \\text{tf}(t, d) \\times \\text{idf}(t)$$\n",
        "\n",
        "*tf* - term-frequency - частотность слова `t` в конкретном документе `d` (рецензии в нашем случае). Это ровно то, что мы уже считали.\n",
        "\n",
        "*idf* - inverse document-frequency - коэффициент, который тем больше, чем в меньшем числе документов встречалось данное слово. Считается как-нибудь так:\n",
        "$$\\text{idf}(t) = \\text{log}\\frac{1 + n_d}{1 + n_{d(t)}} + 1$$\n",
        "где $n_d$ - число всех документов, а $n_{d(t)}$ - число документов со словом `t`.\n",
        "\n",
        "Использовать его просто - нужно заменить `CountVectorizer` на `TfidfVectorizer`.\n",
        "\n",
        "**Задание** Попробуйте запустить `TfidfVectorizer`. Посмотрите на ошибки, которые он научился исправлять, и на ошибки, которые он начал делать - по сравнению с `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3DjjiJglvT3"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(train_df['review'], train_df['is_positive'])\n",
        "\n",
        "eval_model(model, test_df, 'review')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAFYAV8cZC7U"
      },
      "outputs": [],
      "source": [
        "print('Positive' if test_df['is_positive'].iloc[1] else 'Negative')\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[1], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qovj9ugah86y"
      },
      "source": [
        "НАпример слово environment - TfidfVectorizer видит таким, что environment вносит положительную окраску отзыву, в то время как CountVectorizer считал это слово вносящим отрицательную окраску отзыву."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41pQL7QhZJ6p"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_df['review'])\n",
        "incorrect_pred_index = np.random.choice(np.where(preds != test_df['is_positive'])[0])\n",
        "\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[incorrect_pred_index],\n",
        "                     vec=vectorizer, targets=['positive'], target_names=['negative', 'positive'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4oRlGGriMEp"
      },
      "outputs": [],
      "source": [
        "import eli5\n",
        "eli5.show_weights(classifier, vec=vectorizer, top=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdujXL5UjOFN"
      },
      "source": [
        "Важность токенов и вес - тоже сильно изменились. А вот как понять что для каждого векторайзера есть ошибка и как отличить, где ошибался один из них но не ошибался другой  - я не могу понять. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe_CJxQ0tFP9"
      },
      "source": [
        "### N-граммы слов\n",
        "\n",
        "До сих пор мы смотрели на тексты как на мешок слов - но очевидно, что есть разница между `good movie` и `not good movie`.\n",
        "\n",
        "Добавим информацию (хоть какую-то) о последовательностях слов - будем извлекать еще и биграммы слов.\n",
        "\n",
        "В Vectorizer'ах для этого есть параметр `ngram_range=(n_1, n_2)` - он говорит, что нужны n_1-...n_2-граммы.\n",
        "\n",
        "**Задание** Попробуйте увеличенный range и поинтерпретируйте полученный результат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDpdrT0HuKYN"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(2, 4))\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(train_df['review'], train_df['is_positive'])\n",
        "\n",
        "eval_model(model, test_df, 'review')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUVvokpul5Yz"
      },
      "source": [
        "при (ngram_range=(2, 3) Качество модели немного упало (по сравнению с ngram_range=(1, 2)) - думаю, это можно объяснить тем, что триграмы вносят некоторую путаницу в модель.\n",
        "\n",
        "(ngram_range=(2, 4) - качество падает еще сильнее до 85.88% на  тесте\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrBoThj6wl2F"
      },
      "source": [
        "### N-граммы символов\n",
        "\n",
        "Символьные n-граммы дают простой способ выучить полезные корни и суффиксы, не связываясь с этой вашей лингвистикой - только статистика, только хардкор.\n",
        "\n",
        "Например, слово `badass` мы можем представить в виде такой последовательности триграмм:\n",
        "\n",
        "`##b #ba bad ada das ass ss# s##`\n",
        "\n",
        "So interpretable, неправда ли?\n",
        "\n",
        "Реализовать это дело всё так же просто - нужно поставить `analyzer='char'` в вашем любимом Vectorizer'е и выбрать размер `ngram_range`.\n",
        "\n",
        "**Задание** Запилите классификатор на n-граммах символов и визуализируйте его."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QFaWmUrGyY3n"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(2, 6), max_features=20000, analyzer='char')\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(train_df['review'], train_df['is_positive'])\n",
        "\n",
        "eval_model(model, test_df, 'review')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9E1E1Bn8yvhq"
      },
      "outputs": [],
      "source": [
        "print('Positive' if test_df['is_positive'].iloc[1] else 'Negative')\n",
        "eli5.show_prediction(classifier, test_df['review'].iloc[1], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fZ6I8mN0VPU"
      },
      "source": [
        "## Подключаем лингвистику"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkywIvbp4N-L"
      },
      "source": [
        "### Лемматизация и стемминг\n",
        "\n",
        "Если присмотреться, можно найти формы одного слова с разной семантической окраской по мнению классификатора. Или нет?\n",
        "\n",
        "**Задание** Найти формы слова с разной семантической окраской.\n",
        "\n",
        "Поверя, что они есть, попробуем что-нибудь с этим сделать.\n",
        "\n",
        "Например, лемматизируем - сведем к начальной форме все слова. Поможет в этом библиотека spacy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S5CTTdtxI5yv"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# nlp = spacy.load('en', disable=['parser'])\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "docs = [doc for doc in nlp.pipe(train_df.review.values[:50])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bXs8Ia_bqeS0"
      },
      "outputs": [],
      "source": [
        "for token in docs[0]:\n",
        "    print(token.text, token.lemma_, token.ent_iob_, token.ent_type_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pfup3O5r30m"
      },
      "source": [
        "**Задание** Сделайте классификатор на лемматизированных текстах.\n",
        "\n",
        "Более простой способ нормализации слов - использовать стемминг. Он немного тупой, не учитывает контекст, но иногда оказывается даже эффективнее лемматизации - а, главное, быстрее.\n",
        "\n",
        "По сути это просто набор правил, как обрезать слово, чтобы получить основу (stem):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4xETkcyy1uT"
      },
      "source": [
        "### Лемматизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbmy28uuxNWI"
      },
      "outputs": [],
      "source": [
        "train_df['lemmas'] = train_df['review'].apply(lambda row: ' '.join([token.lemma_ for token in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4rEYbbnvkLQ"
      },
      "outputs": [],
      "source": [
        "test_df['lemmas'] = test_df['review'].apply(lambda row: ' '.join([token.lemma_ for token in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgcvES1AxOLr"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "model = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "model.fit(train_df['lemmas'], train_df['is_positive'])\n",
        "\n",
        "eval_model(model, test_df, 'lemmas')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiCK5IvkxOO5"
      },
      "outputs": [],
      "source": [
        "print('Positive' if test_df['is_positive'].iloc[1] else 'Negative')\n",
        "eli5.show_prediction(classifier, test_df['lemmas'].iloc[1], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxGSEqHNsfHy"
      },
      "source": [
        "**Задание** Попробуйте вместо лемм классифицировать основы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV3KoJ3szicj"
      },
      "source": [
        "### Стемминг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr0w_hVyrqFx"
      },
      "outputs": [],
      "source": [
        "from nltk import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "print(stemmer.stem('become'))\n",
        "print(stemmer.stem('becomes'))\n",
        "print(stemmer.stem('became'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOCMs-SRzn9r"
      },
      "outputs": [],
      "source": [
        "train_df['stemms'] = train_df['review'].apply(lambda row: ' '.join([stemmer.stem(word) for word in row.split()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3AgpivHv19C"
      },
      "outputs": [],
      "source": [
        "test_df['stemms'] = test_df['review'].apply(lambda row: ' '.join([stemmer.stem(word) for word in row.split()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAt5j_pyzxT3"
      },
      "outputs": [],
      "source": [
        "model.fit(train_df['stemms'], train_df['is_positive'])\n",
        "\n",
        "eval_model(model, test_df, 'stemms')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1I73KO-Oird"
      },
      "source": [
        "стемминг, показал себя чуть хуже лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT__HmNpzxLI"
      },
      "outputs": [],
      "source": [
        "print('Positive' if test_df['is_positive'].iloc[1] else 'Negative')\n",
        "eli5.show_prediction(classifier, test_df['stemms'].iloc[1], vec=vectorizer, \n",
        "                     targets=['positive'], target_names=['negative', 'positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1NBpkwuspBX"
      },
      "source": [
        "### NER\n",
        "\n",
        "В текстах рецензий очень много именованных сущностей. Вот, например:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xki8Maf9MrVY"
      },
      "outputs": [],
      "source": [
        "displacy.render(docs[0], style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGhcnuZSteHc"
      },
      "source": [
        "Вообще говоря, почему вдруг какой-нибудь Депп должен нести семантическую окраску? Однако оказывается, что классификатор выучивает, что какие-то имена чаще в положительных рецензиях - или наоборот. Это похоже на переобучение - почему бы не попробовать вырезать сущности?\n",
        "\n",
        "**Задание** Удалите из текстов какие-то из сущностей, пользуясь координатами из запикленных файлов. Описание сущностей можно посмотреть [здесь](https://spacy.io/api/annotation#named-entities). Запустите классификатор."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKFemkH3-uXT"
      },
      "source": [
        "### Заменим сущности на теги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHKBPPR9Osla"
      },
      "outputs": [],
      "source": [
        "train_df['org_person'] = train_df['review'].apply(lambda row: ' '.join([ent.text if not ent.ent_type_ else ent.ent_type_ for ent in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJdfq5U5-0wb"
      },
      "outputs": [],
      "source": [
        "test_df['org_person'] = test_df['review'].apply(lambda row: ' '.join([ent.text if not ent.ent_type_ else ent.ent_type_ for ent in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qGpGjViWIFE"
      },
      "outputs": [],
      "source": [
        "train_df['org_person'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzFoOlWUOsoK"
      },
      "outputs": [],
      "source": [
        "model.fit(train_df['org_person'], train_df['is_positive'])\n",
        "\n",
        "eval_model(model, test_df, 'org_person')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we5FlD5PeIog"
      },
      "source": [
        "Метрика немного выросла. Было 88,28% у TFIDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5QGPgdveESw"
      },
      "source": [
        "Теперь уберем дубли типа DATE DATE DATE DATE = DATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTWntmH6h92L"
      },
      "outputs": [],
      "source": [
        "def delete_dubles(text):\n",
        "\n",
        "  new_list = text.split()\n",
        "  new_text = [new_list[i] for i in range(len(new_list) - 1) if new_list[i] != new_list[i+1]] + [new_list[-1]]\n",
        "\n",
        "  return ' '.join(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ1BTWz4kXZW"
      },
      "outputs": [],
      "source": [
        "train_df['org_person_without_dubles'] = train_df['org_person'].apply(delete_dubles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxjZ7zszKB2B"
      },
      "outputs": [],
      "source": [
        "test_df['org_person_without_dubles'] = test_df['org_person'].apply(delete_dubles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyTRG9_skC7q"
      },
      "outputs": [],
      "source": [
        "train_df['org_person'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiPA9jTElDH2"
      },
      "outputs": [],
      "source": [
        "train_df['org_person_without_dubles'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkfNFtDOlH5X"
      },
      "outputs": [],
      "source": [
        "model.fit(train_df['org_person_without_dubles'], train_df['is_positive'])\n",
        "\n",
        "eval_model(model, test_df, 'org_person_without_dubles')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw6ItjCKq3tl"
      },
      "source": [
        "Когда убрал дубли - метрика чуть выросла!!! вау круто"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2fHA70b0zEZ"
      },
      "source": [
        "## Включаем дип лёрнинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1VCrM671XO5"
      },
      "source": [
        "Мы тут пришли deep learning'ом заниматься, а делаем почему-то модель на логистической регрессии. Как так?\n",
        "\n",
        "Попробуем запустить относительно стандартную модель для классификации текстов - сверточная сеть поверх словных эмбеддингов.\n",
        "\n",
        "Разбираться, что это за зверь, будем на следующих занятиях, а пока будем просто им пользоваться :)\n",
        "\n",
        "Каждое предложение нужно представлять набором слов - и сразу же начинаются проблемы. Во-первых, как ограничить длину предложения?\n",
        "\n",
        "Прикинем по гистограмме, какая длина нам подходит:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02Kv8YUPbhzG"
      },
      "outputs": [],
      "source": [
        "train_df['review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O477ZV1t1WIO"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_, _, hist = plt.hist(train_df.review.apply(lambda text: len(text.split())), bins='auto')\n",
        "hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXO4xi0u5m8l"
      },
      "source": [
        "Кроме этого, нужно перенумеровать как-то слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIMGE7L-55fs"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "words_counter = Counter((word for text in train_df.review for word in text.lower().split()))\n",
        "\n",
        "word2idx = {\n",
        "    '': 0,\n",
        "    '<unk>': 1\n",
        "}\n",
        "for word, count in words_counter.most_common():\n",
        "    if count < 10:\n",
        "        break\n",
        "        \n",
        "    word2idx[word] = len(word2idx)\n",
        "    \n",
        "print('Words count', len(word2idx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTptlmd1yD3J"
      },
      "source": [
        "**Задание** Сконвертируйте данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPP0cYdJ5VkE"
      },
      "outputs": [],
      "source": [
        "def convert(texts, word2idx, max_text_len):\n",
        "    data = np.zeros((len(texts), max_text_len), dtype=np.int)\n",
        "    \n",
        "    for inx, text in enumerate(texts):\n",
        "        result = []\n",
        "        for word in text.split():\n",
        "            if word in word2idx:\n",
        "                result.append(word2idx[word])\n",
        "        padding = [0]*(max_text_len - len(result))\n",
        "        data[inx] = np.array(padding + result[-max_text_len:], dtype=np.int)\n",
        "    return data\n",
        "\n",
        "X_train = convert(train_df.review, word2idx, 1000)\n",
        "X_test = convert(test_df.review, word2idx, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYb-p5ioyLUZ"
      },
      "source": [
        "Поставим учиться модельку на keras.\n",
        "\n",
        "*Напоминание*: на keras, чтобы обучить модель, нужно\n",
        "1. Определить модель, например:\n",
        "```python \n",
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=NUM_WORDS))\n",
        "```\n",
        "2. Задать функцию потерь и оптимизатор:\n",
        "```python\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "3. Запустить обучение:\n",
        "```python\n",
        "model.fit(X_train, y_train, \n",
        "          batch_size=32,\n",
        "          epochs=3,\n",
        "          validation_data=(X_test, y_test))\n",
        "```\n",
        "\n",
        "В NLP чаще всего ставятся задачи классификации, поэтому нужно запомнить такие функции потерь:\n",
        "\n",
        "*   **categorical_crossentropy** - для многоклассовой классификации, в качестве меток должны передаваться one-hot-encoding вектора\n",
        "*   **sparse_categorical_crossentropy** - аналогично предыдущему, но в качестве меток нужно передавать просто индексы соответствующих классов\n",
        "*   **binary_crossentropy** - для бинарной классификации\n",
        "\n",
        "\n",
        "В качестве оптимизатора обычно используют `sgd` или `adam`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ncrq09zRxEvN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KddjCCo-w50h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDjri3167vFf"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=len(word2idx), output_dim=64, input_shape=(X_train.shape[1],)),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(units=10, activation='relu'),\n",
        "    Dense(units=10, activation='relu'),\n",
        "\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw93gTmq8gZl"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, train_df.is_positive, batch_size=128, epochs=10, \n",
        "          validation_data=(X_test, test_df.is_positive))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBGdVRQTyynD"
      },
      "source": [
        "**Задание** Подсчитайте качество модели на тесте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBGrwMdNNlTy"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oyvyiT5Qxkr"
      },
      "outputs": [],
      "source": [
        "preds = np.around(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtB3O9kMPS2Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_df.is_positive, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYD8swF5PjgR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "hw_lesson_6.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}