{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import ngrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk import collocations \n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from pymystem3 import Mystem\n",
        "import re\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from razdel import tokenize\n",
        "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_2e_MR_fT68X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbJ4nF8sTorO",
        "outputId": "bcb5886e-5316-49f2-86ae-f68396b4708b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "my_stopwords = stopwords.words('russian')\n",
        "# noise = stopwords.words('russian') + list(punctuation)\n",
        "noise = stopwords.words('russian')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive)\n",
        "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative)\n",
        "df = positive.append(negative)"
      ],
      "metadata": {
        "id": "LXJHr-qPT37e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)\n"
      ],
      "metadata": {
        "id": "fHlEOZAqU_qS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokens_importance(maxdf, mindf):\n",
        "    \n",
        "    tfidf_vect = TfidfVectorizer(max_df=maxdf, # не берем слова что выше тресхолда\n",
        "                                 min_df=mindf, # не берем что ниже тресхолда\n",
        "#                                  max_features=1000, \n",
        "#                                  stop_words=noise,\n",
        "                                 )\n",
        "    \n",
        "    bow = tfidf_vect.fit_transform(x_train)\n",
        "    clf = LogisticRegression(random_state=42)\n",
        "    clf.fit(bow, y_train)\n",
        "    \n",
        "    pred = clf.predict(tfidf_vect.transform(x_test))\n",
        "    print(f'max_df= {maxdf} min_df= {mindf}')\n",
        "    print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "id": "GpV_e2FFVDma"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Берем все токены - f1-score получается низкая\n",
        "get_tokens_importance(1, 1)"
      ],
      "metadata": {
        "id": "w0xvjGjqVFSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cca638f-cb02-4eed-a681-6dc45f41857b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 1 min_df= 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.53      0.66     47540\n",
            "    positive       0.22      0.68      0.33      9169\n",
            "\n",
            "    accuracy                           0.55     56709\n",
            "   macro avg       0.56      0.60      0.50     56709\n",
            "weighted avg       0.79      0.55      0.61     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_tokens_importance(0.7, 0.15)"
      ],
      "metadata": {
        "id": "XKIgbuxwVFPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8937afee-c902-4096-833f-b630c3bfd79f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 0.7 min_df= 0.15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.34      0.61      0.44     15805\n",
            "    positive       0.78      0.55      0.65     40904\n",
            "\n",
            "    accuracy                           0.57     56709\n",
            "   macro avg       0.56      0.58      0.54     56709\n",
            "weighted avg       0.66      0.57      0.59     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_tokens_importance(0.3, 1)"
      ],
      "metadata": {
        "id": "n8AqvIC8VFNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58660e2-dd84-4c51-e365-08742ed2b9f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_df= 0.3 min_df= 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.77      0.75     26632\n",
            "    positive       0.78      0.75      0.77     30077\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На мой взгляд, менее встречающиеся токены важнее\n"
      ],
      "metadata": {
        "id": "I7jyI1RgVNM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2\n"
      ],
      "metadata": {
        "id": "aT1_YZ6uV9dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "# corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
        "corpus = [token for tweet in df.text for token in word_tokenize(tweet)]\n",
        "print(len(corpus))\n",
        "corpus[:10]\n"
      ],
      "metadata": {
        "id": "jKC8Cw_EVFK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48846652-91f1-42ec-a35d-ee5e0bbbc4ad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4027060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@', 'first_timee', 'хоть', 'я', 'и', 'школота', ',', 'но', 'поверь', ',']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]"
      ],
      "metadata": {
        "id": "mftU95YLVFIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67eb93a1-6aa1-4faa-f2f5-d409c01c135f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('(', 212404),\n",
              " (')', 194005),\n",
              " (',', 188295),\n",
              " (':', 177675),\n",
              " ('@', 149978),\n",
              " ('не', 69472),\n",
              " ('!', 66923),\n",
              " ('.', 57595),\n",
              " ('и', 55166),\n",
              " ('в', 52902)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eJk4NyXDXAiy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}