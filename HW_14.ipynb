{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ea501f6a",
      "metadata": {
        "id": "ea501f6a"
      },
      "source": [
        "# Практическое задание к уроку 14. Transfer learning\n",
        "\n",
        "\n",
        "1. Взять данные из\n",
        "\n",
        "https://www.kaggle.com/datasets/mrapplexz/bashim-quotes\n",
        "\n",
        "обучить модель GPT для генерации своих цитат\n",
        "\n",
        "2. Взять новостные данные из\n",
        "\n",
        "https://github.com/natasha/corus\n",
        "\n",
        "load_lenta2\n",
        "\n",
        "нам понадобиться сам текст и заголовок\n",
        "\n",
        "обучить модель T5/ или GPT для генерации заголовков для статей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff82a98",
      "metadata": {
        "id": "eff82a98"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATASET_PATH = 'dataset.jsonl'\n",
        "\n",
        "\n",
        "with open(DATASET_PATH) as f: \n",
        "    df = pd.read_json(DATASET_PATH, lines=True).set_index('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "564d8e02",
      "metadata": {
        "id": "564d8e02",
        "outputId": "91acf9fe-07b3-4526-9718-a8f908ddaf1d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-08-30 11:24:00+00:00</td>\n",
              "      <td>22010.0</td>\n",
              "      <td>&lt;Ares&gt; ppdv, все юниксы очень дружелюбны.. они...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004-08-30 11:25:00+00:00</td>\n",
              "      <td>25105.0</td>\n",
              "      <td>&lt;томатик_рад&gt; а ты не чувствуешь красоту мира?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004-08-30 11:27:00+00:00</td>\n",
              "      <td>7192.0</td>\n",
              "      <td>&lt;Дор&gt; \"мышка, почему у тебя такие большие глаз...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004-08-30 11:28:00+00:00</td>\n",
              "      <td>29169.0</td>\n",
              "      <td>&lt;PPDV[os2]&gt; \"Мальчики, вы что больные, бегать ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2004-08-30 11:26:00+00:00</td>\n",
              "      <td>7140.0</td>\n",
              "      <td>&lt;Ohtori_Akio&gt; мы - как разработчики - живём с ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        date   rating  \\\n",
              "id                                      \n",
              "1  2004-08-30 11:24:00+00:00  22010.0   \n",
              "2  2004-08-30 11:25:00+00:00  25105.0   \n",
              "3  2004-08-30 11:27:00+00:00   7192.0   \n",
              "4  2004-08-30 11:28:00+00:00  29169.0   \n",
              "5  2004-08-30 11:26:00+00:00   7140.0   \n",
              "\n",
              "                                                 text  \n",
              "id                                                     \n",
              "1   <Ares> ppdv, все юниксы очень дружелюбны.. они...  \n",
              "2   <томатик_рад> а ты не чувствуешь красоту мира?...  \n",
              "3   <Дор> \"мышка, почему у тебя такие большие глаз...  \n",
              "4   <PPDV[os2]> \"Мальчики, вы что больные, бегать ...  \n",
              "5   <Ohtori_Akio> мы - как разработчики - живём с ...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14c35aa8",
      "metadata": {
        "id": "14c35aa8",
        "outputId": "32fd2043-fab9-48b6-d4e9-e23b51b3e3dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(81497, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcdbde5f",
      "metadata": {
        "id": "dcdbde5f"
      },
      "source": [
        "##### Препроцессинг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e7ac2b",
      "metadata": {
        "id": "91e7ac2b"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = df.loc[:5000, 'text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e96f21",
      "metadata": {
        "id": "62e96f21"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe8b1eef",
      "metadata": {
        "id": "fe8b1eef"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def build_text_files(data_json, dest_path):\n",
        "    f = open(dest_path, 'w')\n",
        "    data = ''\n",
        "    for texts in data_json:\n",
        "        summary = str(texts).strip()\n",
        "        summary = re.sub(r\"\\[\\w+\\]\", \"\", summary)\n",
        "        summary = re.sub(r\"<[\\w+,\\!, -]>\", \"\", summary)\n",
        "        summary = re.sub(r\"<\\w+>\", \"\", summary)\n",
        "        summary = re.sub(r\"\\s\", \" \", summary)\n",
        "        data += summary + \"  \"\n",
        "    f.write(data)\n",
        "  \n",
        "build_text_files(train,'train_dataset.txt')\n",
        "build_text_files(test,'test_dataset.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d05497",
      "metadata": {
        "id": "60d05497"
      },
      "outputs": [],
      "source": [
        "with open('train_dataset.txt') as f: \n",
        "  train_dataset = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e9ff8e1",
      "metadata": {
        "id": "9e9ff8e1"
      },
      "source": [
        "##### Загрузка токенайзера и создание датасетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf21beee",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0489337b75aa436696348a3ee79b80a2",
            "898f019b16134fde9b5c04d443c2c028",
            "999f3fe38a8f4636b3e41f19cb23179f"
          ]
        },
        "id": "cf21beee",
        "outputId": "728c8090-f547-422f-9f32-9c98b441316b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0489337b75aa436696348a3ee79b80a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "898f019b16134fde9b5c04d443c2c028",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.63M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "999f3fe38a8f4636b3e41f19cb23179f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import AutoTokenizer\n",
        "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e27f365",
      "metadata": {
        "id": "0e27f365"
      },
      "outputs": [],
      "source": [
        "train_path = 'train_dataset.txt'\n",
        "test_path = 'test_dataset.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c041646",
      "metadata": {
        "id": "4c041646",
        "outputId": "13ec7670-d052-4bc0-a0c2-edfe1421b063"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "def load_dataset(train_path, test_path, tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "\n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset, test_dataset, data_collator\n",
        "\n",
        "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e398b7",
      "metadata": {
        "id": "59e398b7"
      },
      "source": [
        "##### Загрузка и обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45eabd15",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4dd3706dc0d84e67a23c4ee4051b3797"
          ]
        },
        "id": "45eabd15",
        "outputId": "f8cbf7a6-70df-4e78-ee44-5635e18f461c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dd3706dc0d84e67a23c4ee4051b3797",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/526M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f68e14a",
      "metadata": {
        "id": "0f68e14a"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"gdrive/MyDrive/GPT/gpt2-chief\", #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=3, # number of training epochs\n",
        "    per_device_train_batch_size=4, # batch size for training\n",
        "    per_device_eval_batch_size=4,  # batch size for evaluation\n",
        "    eval_steps = 400, # Number of update steps between two evaluations.\n",
        "    save_steps=800, # after # steps model is saved\n",
        "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d059730",
      "metadata": {
        "id": "6d059730"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e478840b",
      "metadata": {
        "id": "e478840b",
        "outputId": "20f5ac15-f53d-499b-ee2f-0ec3a0d27879"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 467\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 351\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='351' max='351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [351/351 42:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=351, training_loss=4.383714637865029, metrics={'train_runtime': 2538.1042, 'train_samples_per_second': 0.552, 'train_steps_per_second': 0.138, 'total_flos': 91517534208000.0, 'train_loss': 4.383714637865029, 'epoch': 3.0})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2701819",
      "metadata": {
        "id": "b2701819"
      },
      "source": [
        "##### Сохранение модели и токенизатора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "319247f2",
      "metadata": {
        "id": "319247f2",
        "outputId": "8c0db898-c6f7-46d5-e34d-4169b12d7e78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to gdrive/MyDrive/GPT/gpt2-chief\n",
            "Configuration saved in gdrive/MyDrive/GPT/gpt2-chief/config.json\n",
            "Model weights saved in gdrive/MyDrive/GPT/gpt2-chief/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8781e681",
      "metadata": {
        "id": "8781e681",
        "outputId": "db762185-381c-4862-9ff5-d2969218dcab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tokenizer config file saved in gdrive/MyDrive/GPT/gpt2-chief/tokenizer_config.json\n",
            "Special tokens file saved in gdrive/MyDrive/GPT/gpt2-chief/special_tokens_map.json\n",
            "Configuration saved in gdrive/MyDrive/GPT/model_gpt_chf/config.json\n",
            "Model weights saved in gdrive/MyDrive/GPT/model_gpt_chf/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "tokenizer.save_pretrained('gdrive/MyDrive/GPT/gpt2-chief')\n",
        "model.save_pretrained('gdrive/MyDrive/GPT/model_gpt_chf')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d855ed",
      "metadata": {
        "id": "85d855ed"
      },
      "source": [
        "##### Генерация текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7bd1c2b",
      "metadata": {
        "id": "a7bd1c2b",
        "outputId": "04f06819-fa4f-46d6-c0d4-9e099b2dba5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file gdrive/MyDrive/GPT/gpt2-chief/vocab.json\n",
            "loading file gdrive/MyDrive/GPT/gpt2-chief/merges.txt\n",
            "loading file gdrive/MyDrive/GPT/gpt2-chief/tokenizer.json\n",
            "loading file gdrive/MyDrive/GPT/gpt2-chief/added_tokens.json\n",
            "loading file gdrive/MyDrive/GPT/gpt2-chief/special_tokens_map.json\n",
            "loading file gdrive/MyDrive/GPT/gpt2-chief/tokenizer_config.json\n",
            "loading configuration file gdrive/MyDrive/GPT/model_gpt_chf/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gdrive/MyDrive/GPT/model_gpt_chf\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading weights file gdrive/MyDrive/GPT/model_gpt_chf/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gdrive/MyDrive/GPT/model_gpt_chf.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gdrive/MyDrive/GPT/gpt2-chief\")\n",
        "model1 = AutoModelForCausalLM.from_pretrained(\"gdrive/MyDrive/GPT/model_gpt_chf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f928da",
      "metadata": {
        "id": "f3f928da",
        "outputId": "9132c264-ae18-4d8b-9409-37723c5d6882"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "добрый день  <@dr-zan> у нас в городе есть только один человек, который может сказать что-то такое, чего не сказал бы ни один нормальный человек.   а кто нибудь знает где можно скачать драйвер на винду\n"
          ]
        }
      ],
      "source": [
        "prefix = \"добрый день \"\n",
        "tokens = tokenizer(prefix, return_tensors='pt')\n",
        "size = tokens['input_ids'].shape[1]\n",
        "output = model.generate( \n",
        "    **tokens, \n",
        "    do_sample=False,\n",
        "    max_length=+50,\n",
        "    repetition_penalty=5., \n",
        "    temperature=0.5,\n",
        "    num_beams=10,\n",
        ")\n",
        "\n",
        "decoded = tokenizer.decode(output[0])\n",
        "result = decoded[len(prefix):]\n",
        "print(prefix + result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "265fcc91",
      "metadata": {
        "id": "265fcc91"
      },
      "source": [
        "#### 2. Взять новостные данные из\n",
        "\n",
        "https://github.com/natasha/corus\n",
        "\n",
        "load_lenta2\n",
        "\n",
        "нам понадобиться сам текст и заголовок\n",
        "\n",
        "обучить модель T5/ или GPT для генерации заголовков для статей"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a4446ec",
      "metadata": {
        "id": "4a4446ec"
      },
      "source": [
        "##### Загрузка и подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a291fc",
      "metadata": {
        "id": "c9a291fc",
        "outputId": "3363626a-0005-4fbd-b911-6382e076091c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "--2022-07-18 12:18:08--  https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2014.tar.bz2\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/141595206/7f9b5080-d24d-11e8-8b67-cd6a839c2b29?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220718%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220718T091809Z&X-Amz-Expires=300&X-Amz-Signature=dfb03e6818abc4846fac12924f95256fe8381989a9df753a56e2c5ce1f31caf4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141595206&response-content-disposition=attachment%3B%20filename%3Dnews-articles-2014.tar.bz2&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-07-18 12:18:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/141595206/7f9b5080-d24d-11e8-8b67-cd6a839c2b29?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220718%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220718T091809Z&X-Amz-Expires=300&X-Amz-Signature=dfb03e6818abc4846fac12924f95256fe8381989a9df753a56e2c5ce1f31caf4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141595206&response-content-disposition=attachment%3B%20filename%3Dnews-articles-2014.tar.bz2&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 318705497 (304M) [application/octet-stream]\n",
            "Saving to: 'news-articles-2014.tar.bz2'\n",
            "\n",
            "news-articles-2014. 100%[===================>] 303.94M  15.0MB/s    in 15s     \n",
            "\n",
            "2022-07-18 12:18:25 (19.8 MB/s) - 'news-articles-2014.tar.bz2' saved [318705497/318705497]\n",
            "\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "--2022-07-18 12:18:25--  https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2015-part1.tar.bz2\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/141595206/9d67b600-d24b-11e8-9f0f-5cb826a4ecec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220718%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220718T091825Z&X-Amz-Expires=300&X-Amz-Signature=0ec8d3cf2c180b22583ff7790029b60c61e3c8a6ea296f1b99974515dc778c2d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141595206&response-content-disposition=attachment%3B%20filename%3Dnews-articles-2015-part1.tar.bz2&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-07-18 12:18:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/141595206/9d67b600-d24b-11e8-9f0f-5cb826a4ecec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220718%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220718T091825Z&X-Amz-Expires=300&X-Amz-Signature=0ec8d3cf2c180b22583ff7790029b60c61e3c8a6ea296f1b99974515dc778c2d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141595206&response-content-disposition=attachment%3B%20filename%3Dnews-articles-2015-part1.tar.bz2&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 531645289 (507M) [application/octet-stream]\n",
            "Saving to: 'news-articles-2015-part1.tar.bz2'\n",
            "\n",
            "news-articles-2015- 100%[===================>] 507.02M  5.53MB/s    in 31s     \n",
            "\n",
            "2022-07-18 12:18:57 (16.2 MB/s) - 'news-articles-2015-part1.tar.bz2' saved [531645289/531645289]\n",
            "\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "--2022-07-18 12:18:57--  https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2015-part2.tar.bz2\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/141595206/24695e00-d24d-11e8-9d0f-ab0a1d9ac829?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220718%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220718T091857Z&X-Amz-Expires=300&X-Amz-Signature=6269a9d5856f7830e6ca1c22ad2d501607a316756be3815e0447b6a3db3a75c6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141595206&response-content-disposition=attachment%3B%20filename%3Dnews-articles-2015-part2.tar.bz2&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-07-18 12:18:57--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/141595206/24695e00-d24d-11e8-9d0f-ab0a1d9ac829?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220718%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220718T091857Z&X-Amz-Expires=300&X-Amz-Signature=6269a9d5856f7830e6ca1c22ad2d501607a316756be3815e0447b6a3db3a75c6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141595206&response-content-disposition=attachment%3B%20filename%3Dnews-articles-2015-part2.tar.bz2&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 445562164 (425M) [application/octet-stream]\n",
            "Saving to: 'news-articles-2015-part2.tar.bz2'\n",
            "\n",
            "news-articles-2015- 100%[===================>] 424.92M  25.4MB/s    in 17s     \n",
            "\n",
            "2022-07-18 12:19:14 (24.8 MB/s) - 'news-articles-2015-part2.tar.bz2' saved [445562164/445562164]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2014.tar.bz2\n",
        "!wget https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2015-part1.tar.bz2\n",
        "!wget https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2015-part2.tar.bz2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1736cce",
      "metadata": {
        "id": "c1736cce",
        "outputId": "7fa0fe9c-1c67-440e-bc69-962e52757216"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BuriyRecord(\n",
              "    timestamp=datetime.datetime(2014, 8, 22, 15, 15),\n",
              "    url='http://www.ntv.ru/novosti/1200239/',\n",
              "    edition=None,\n",
              "    topics='novosti',\n",
              "    title='Россияне на юношеских Олимпийских играх в пятницу завоевали восемь медалей',\n",
              "    text='В пятницу российские спортсмены на\\nюношеских Олимпийских играх в китайском Нанкине\\nзавоевали еще восемь наград \\x97 две золотые, три серебряные и три бронзовые.\\nТяжелоатлет Хетаг Хугаев завоевал золото в весовой категории до 85 кг. Розалия Насретдинова первенствовала в плавании на дистанции 50 метров вольным стилем.\\nЕвгений Рылов принес россиянам серебро в плавании на дистанции 200 метров на спине. Он же вместе с Александром Садовниковым, Розалией Насретдиновой и Дарьей Устиновой стал вторым в смешанной комбинированной эстафете 4х100 м.\\nШтангистка Светлана Щербакова завоевала серебро в весовой категории свыше 63 кг.\\nКроме того, та же Дарья Устинова завоевала бронзу в плавании на дистанции 50 м вольным стилем, а Антон Чупков \\x97 награду того же достоинства на дистанции 50 м на спине.\\nПо итогам шестого дня сборная России сохранила второе место в командном зачете. На ее счету 29 медалей (11 золотых, 10 серебряных и 8 бронзовых). Лидирует китайская команда с 35 наградами (17 \\x97 7 \\x97 11).'\n",
              ")"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from corus import load_buriy_news\n",
        "\n",
        "paths = [\n",
        "    'news-articles-2014.tar.bz2',\n",
        "    'news-articles-2015-part1.tar.bz2',\n",
        "    'news-articles-2015-part2.tar.bz2'\n",
        "]\n",
        "records = (\n",
        "    record\n",
        "    for path in paths\n",
        "    for record in load_buriy_news(path)\n",
        ")\n",
        "next(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb04b60f",
      "metadata": {
        "id": "cb04b60f"
      },
      "outputs": [],
      "source": [
        "data = [(record.title, record.text) for record in records]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1de6e9e1",
      "metadata": {
        "id": "1de6e9e1",
        "outputId": "f3923d19-6a7d-44c7-8bc8-b640e6540643"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Российские журналисты попали под минометный об...</td>\n",
              "      <td>Пётр Михайлов\\n, сотрудник пресс-службы провоз...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ЕС призывает РФ вывести гуманитарный конвой с ...</td>\n",
              "      <td>Себастьен Брабант\\n, представитель ЕС: «Мы сож...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Яценюк: у нас есть своя гуманитарная помощь</td>\n",
              "      <td>Арсений Яценюк заявил, что Украина не нуждаетс...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Музей варежки открывает выставку художника-инв...</td>\n",
              "      <td>Сегодня в петербургском музее варежки открылас...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Тихонов станет единственным кандидатом от Росс...</td>\n",
              "      <td>Александр Тихонов (на фото) будет единственным...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Российские журналисты попали под минометный об...   \n",
              "1  ЕС призывает РФ вывести гуманитарный конвой с ...   \n",
              "2        Яценюк: у нас есть своя гуманитарная помощь   \n",
              "3  Музей варежки открывает выставку художника-инв...   \n",
              "4  Тихонов станет единственным кандидатом от Росс...   \n",
              "\n",
              "                                                text  \n",
              "0  Пётр Михайлов\\n, сотрудник пресс-службы провоз...  \n",
              "1  Себастьен Брабант\\n, представитель ЕС: «Мы сож...  \n",
              "2  Арсений Яценюк заявил, что Украина не нуждаетс...  \n",
              "3  Сегодня в петербургском музее варежки открылас...  \n",
              "4  Александр Тихонов (на фото) будет единственным...  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_news = pd.DataFrame({'title': [record[0] for record in data], 'text': [record[1] for record in data]})\n",
        "df_news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d614fc29",
      "metadata": {
        "id": "d614fc29",
        "outputId": "45199374-8b0f-4fc9-816c-6fb36eb6133b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2154800, 2)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_news.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ebd7296",
      "metadata": {
        "id": "1ebd7296",
        "outputId": "4c4e4dbe-c978-49a9-c9cf-49206e53d0fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(717050, 252)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(len(i) for i in df_news['text'].values), max(len(i) for i in df_news['title'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21bf353a",
      "metadata": {
        "id": "21bf353a"
      },
      "outputs": [],
      "source": [
        "data_news = df_news[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2424b37a",
      "metadata": {
        "id": "2424b37a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(data_news, test_size=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddcc2827",
      "metadata": {
        "id": "ddcc2827",
        "outputId": "17153bcd-60a2-4e1c-f582-aecc0aefce5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['title', 'text'],\n",
              "     num_rows: 425\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['title', 'text'],\n",
              "     num_rows: 75\n",
              " }))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "df_train.reset_index(drop=True, inplace=True)\n",
        "df_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "dataset_train = Dataset.from_pandas(df_train)\n",
        "dataset_test = Dataset.from_pandas(df_test)\n",
        "dataset_train, dataset_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc1ad80",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9c926eb2e3b3436c94c6443fb92a5f21",
            "de9d0379cef5480e8d518019d7a3059d"
          ]
        },
        "id": "7dc1ad80",
        "outputId": "c8c009b8-69f7-4731-c504-c8fe3e7058b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/IlyaGusev/rut5_base_sum_gazeta/resolve/main/spiece.model from cache at /Users/alenakukhta/.cache/huggingface/transformers/9adebe2aa47a25febcf707ee15540f9e440f8d8e79697dae237fc4e6ccad5019.b846524fbcbf3cf81e2302f8087043922ca4c445b4016bf16e707f7e2240a3e6\n",
            "loading file https://huggingface.co/IlyaGusev/rut5_base_sum_gazeta/resolve/main/tokenizer.json from cache at /Users/alenakukhta/.cache/huggingface/transformers/9ea40ad78f35f554a9c607b947515d4e6f2f62e3a6a1ec3fa957e727cddbb635.975331e2a6fea3fd5d8f528410d471fb0f6f16b82a34e658f7a0d5eda5061b99\n",
            "loading file https://huggingface.co/IlyaGusev/rut5_base_sum_gazeta/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/IlyaGusev/rut5_base_sum_gazeta/resolve/main/special_tokens_map.json from cache at /Users/alenakukhta/.cache/huggingface/transformers/6ef3ae62c46b2a0173c15263e19f4443143979a9eefdfc1feab6a709496e7be2.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
            "loading file https://huggingface.co/IlyaGusev/rut5_base_sum_gazeta/resolve/main/tokenizer_config.json from cache at /Users/alenakukhta/.cache/huggingface/transformers/f2a7b6aa9f667eabdf0660f437c38ca43696ef49a86df2e264fc93750ab9abb5.30a9c79b7a80d5e1aa9c5b7d6aff517e04661218d78a71459b4587fa83baa33a\n",
            "Parameter 'function'=<function tokenize at 0x7fbdbff3f3a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c926eb2e3b3436c94c6443fb92a5f21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/54 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de9d0379cef5480e8d518019d7a3059d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "#создаем объект класса токенизатор\n",
        "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_len_txt = 400\n",
        "max_len_tlt = 50\n",
        "\n",
        "def tokenize(batch):\n",
        "    tokenized_input = tokenizer(batch['text'], padding='max_length', truncation=True, max_length=max_len_txt)\n",
        "    tokenized_label = tokenizer(batch['title'], padding='max_length', truncation=True, max_length=max_len_tlt)\n",
        "    tokenized_input['labels'] = tokenized_label['input_ids']\n",
        "\n",
        "    return tokenized_input\n",
        "\n",
        "dataset_train = dataset_train.map(tokenize, batched=True, batch_size=8)\n",
        "dataset_test = dataset_test.map(tokenize, batched=True, batch_size=8)\n",
        "\n",
        "dataset_train.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "dataset_test.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee04c54",
      "metadata": {
        "id": "4ee04c54",
        "outputId": "b49645e5-e4f8-4e62-fed4-62ab67cb1c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['title', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 425\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['title', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 75\n",
              " }))"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_train, dataset_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5f3f4bd",
      "metadata": {
        "id": "b5f3f4bd"
      },
      "outputs": [],
      "source": [
        "dataset_train.save_to_disk('gazeta/train')\n",
        "dataset_test.save_to_disk('gazeta/test')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5b9304",
      "metadata": {
        "id": "1f5b9304"
      },
      "source": [
        "##### Загрузка и обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5782dd32",
      "metadata": {
        "id": "5782dd32",
        "outputId": "c6fd4a24-117a-4089-8faf-4ad73beaafa0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/IlyaGusev/rut5_base_sum_gazeta/resolve/main/config.json from cache at /Users/alenakukhta/.cache/huggingface/transformers/426a325da473aa010e527ee99032b35ce9354913e38282d34e50dd75856c82f7.87df939950b4282d4195b92cd0a6209ec6d3d69e74b13a77d87890cf3a5ded7b\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"cointegrated/rut5-base\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"bos_token_id\": 2,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"max_length\": 200,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"num_beams\": 5,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/IlyaGusev/rut5_base_sum_gazeta/resolve/main/pytorch_model.bin from cache at /Users/alenakukhta/.cache/huggingface/transformers/f4c11e29521f27cff5768a7f18580488bf450ce29ef1e4c8e06f9802e9d6ab42.e3b906d7892e5f268c9d2f19a84d52ddfe543929f0dca80cb66a59459d424a1b\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at IlyaGusev/rut5_base_sum_gazeta.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f6b46e4",
      "metadata": {
        "id": "1f6b46e4",
        "outputId": "6b8bac3a-5f8f-44e8-e8eb-358549b49760"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "#настройки обучения\n",
        "output_dir = 'gazeta/output'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    save_steps=1000,\n",
        "    remove_unused_columns=True, \n",
        "    eval_steps=500,\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d3b2c77",
      "metadata": {
        "id": "4d3b2c77",
        "outputId": "44926ab2-85a3-454a-bf3e-523f5ff946fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['title', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 425\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['title', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 75\n",
              " }))"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_from_disk\n",
        "dataset_train = load_from_disk(\"gazeta/train\")\n",
        "dataset_test = load_from_disk(\"gazeta/test\")\n",
        "dataset_train, dataset_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdfb2608",
      "metadata": {
        "id": "cdfb2608",
        "outputId": "6c06d6be-f3e9-490c-c1c3-5b049b0d6486"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 425\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 639\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='639' max='639' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [639/639 1:43:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.286200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=639, training_loss=2.789409130018828, metrics={'train_runtime': 6190.1052, 'train_samples_per_second': 0.206, 'train_steps_per_second': 0.103, 'total_flos': 677081548800000.0, 'train_loss': 2.789409130018828, 'epoch': 3.0})"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_test\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6288e314",
      "metadata": {
        "id": "6288e314",
        "outputId": "c1004fe3-5a55-497c-9f5a-587ab9ca07bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to gazeta/output/model\n",
            "Configuration saved in gazeta/output/model/config.json\n",
            "Model weights saved in gazeta/output/model/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(output_dir + '/model')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b0d1bd",
      "metadata": {
        "id": "c1b0d1bd"
      },
      "source": [
        "##### Генерация заголовков статей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93be91b",
      "metadata": {
        "id": "f93be91b",
        "outputId": "296458c4-46e3-4c85-eceb-5916076ca903"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text:\n",
            "Из заявления МИД РФ\n",
            ": «21 августа Россия выступила с инициативой принятия Советом Безопасности ООН решения в поддержку доставки гуманитарной помощи на украинский юго-восток. Эта конструктивная российская инициатива была заблокирована США и Литвой».\n",
            "В МИД РФ считают очевидной двуличие такой политики и обвиняют США и их европейских партнеров в «циничном пренебрежении судьбами мирных граждан и наплевательском отношении к международному гуманитарному праву».\n",
            "Из заявления МИД РФ\n",
            ": «Если США пошли против абсолютно неконфронтационного, примиряющего текста, то не остается никаких сомнений в нацеленности Вашингтона на продолжение вооруженного противостояния на Украине. Иначе как попыткой „подорвать“ гуманитарную миссию назвать это нельзя».\n",
            "Real title: МИД РФ: США пытаются сорвать российскую гуманитарную миссию на Украине\n",
            "Pred title: МИД РФ: США и Литва отказались от доставки гуманитарной помощи на Украине\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "INX = 10\n",
        "input_text = dataset_test['text'][INX]\n",
        "input_title = dataset_test['title'][INX]\n",
        "\n",
        "with torch.no_grad():\n",
        "    tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "    source_ids = tokenized_text['input_ids'].to(dtype = torch.long)\n",
        "    source_mask = tokenized_text['attention_mask'].to(dtype = torch.long)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        input_ids = source_ids,\n",
        "        attention_mask = source_mask, \n",
        "        max_length=512,\n",
        "        num_beams=7,\n",
        "        temperature = 1.3,\n",
        "        repetition_penalty=1, \n",
        "        length_penalty=1, \n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2\n",
        "    )\n",
        "\n",
        "    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "print(\"Text:\\n\" + input_text)\n",
        "print(\"Real title: \" + input_title)\n",
        "print(\"Pred title: \" + pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}